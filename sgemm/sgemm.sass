# Kernel: sgemm_kernel_128
#
# SharedSize: 16384
# Params(8):
#   0:0x140:4:4 param_C,
#   1:0x144:4:0 param_m,
#   2:0x148:4:0 param_n,
#   3:0x14c:4:0 param_k,
#   4:0x150:4:0 param_lda,
#   5:0x154:4:0 param_ldb,
#   6:0x158:4:0 param_ldc
#   7:0x15c:4:4 param_D // for diagnostic printf output
#
# Globals:
#   c[0x0][0x160]: texA (the value is 1)
#   c[0x0][0x164]: texB (the value is 0)

<REGISTER_MAPPING>

    // 64 maxtrix C output registers.
    // Use special mapping to avoid register bank conflicts between these registers and the blocking registers.
     3, 2,11,10,19,18,27,26 : cx00y<00-03|16-19>
     7, 6,15,14,23,22,31,30 : cx01y<00-03|16-19>
     1, 0, 9, 8,17,16,25,24 : cx02y<00-03|16-19>
     5, 4,13,12,21,20,29,28 : cx03y<00-03|16-19>
    35,34,43,42,51,50,59,58 : cx32y<00-03|16-19>
    39,38,47,46,55,54,63,62 : cx33y<00-03|16-19>
    33,32,41,40,49,48,57,56 : cx34y<00-03|16-19>
    37,36,45,44,53,52,61,60 : cx35y<00-03|16-19>

    // Double buffered register blocking
    // Any bank conflicts that we can't avoid in these registers we can hide with .reuse flags
    64-79   : j0Ax<00-03|32-35>, j0By<00-03|16-19>
    80-95   : j1Ax<00-03|32-35>, j1By<00-03|16-19>

    // Registers to load A or B
    96-103  : loadX<0-7>

    // Key state registers for main loop and some we reuse for outputing C
    104-127 : track<0-7>, writeS, ldx8, end, tex, readAs, readBs, tid, tid4, tid32, bx, by

    // Temporary registers to calculate the state registers. Reuse the C output registers.
    0-63    : blk, ldx, ldx2, ldx4, k, val<0-2>, xmad<0-1>, tid128

    // Registers to store the results back to global memory. Reuse any register not needed after the main loop.
    64-79   : cs<0-7>, Cy00, Cy04, Cy08, Cy12, cy00, cy04, cy08, cy12
    80-115  : m, n, ldc, ldc1, ldc4, ldc8, ldc12, writeCs, readCs, cx, ci, val3, xmad2, D

</REGISTER_MAPPING>

// Scheduler doesn't handle the dependency flags yet,
// so move these first instructions outside the block that's auto scheduled
--:-:1:-:1      S2R tid, SR_TID.X;   // Set Dep 1
--:-:2:-:1      S2R bx,  SR_CTAID.X; // Set Dep 2
--:-:3:-:1      S2R by,  SR_CTAID.Y; // Set Dep 3

// Instructions in a SCHEDULE_BLOCK are automatically reordered and appropriately stalled for simple dependancies
// Memory dependencies are left up to the auther to deal with manually for now.
<SCHEDULE_BLOCK>

// First 128 threads load A to shared, 2nd 128 loads B to shared
// Note this technique is not possible in cuda or ptx as there's no way to specify a warp-uniform predicate for a memory op

// blk = tid >= 128 ? by   : bx;
// ldx = tid >= 128 ? ldb  : lda;
// tex = tid >= 128 ? texB : texA;
01:-:-:Y:1      ISETP.GE.AND P0, PT, tid, 0x80, PT; // Wait Dep 1
06:-:-:-:1      SEL blk, by, bx, P0;                // Wait Dep 2 & 3
--:-:-:-:1 @!P0 MOV ldx, c[0x0][0x150];
--:-:-:-:1  @P0 MOV ldx, c[0x0][0x154];
--:-:-:-:1 @!P0 MOV32I tex, 0x80000001; // texA
--:-:-:-:1  @P0 MOV32I tex, 0x80000000; // texB

// ldx4 = ldx * 4;
// ldx8 = ldx * 8;
--:-:-:-:1      SHL  ldx4, ldx, 0x2;
--:-:-:-:1      IADD ldx8, ldx4, ldx4;

// tid32  = tid & 31
// tid4   = (tid >> 5) & 3
--:-:-:-:1      LOP.AND tid32,  tid, 0x1f;
--:-:-:-:1      BFE.U32 tid4,   tid, 0x205;

<CODE>

    # Test two alternate means of loading from textures.
    # Block mode is only 3 Gflops faster but this is more for showing what you can do with code sections.
    our $mode = 'block';

    # Linear Mode: 128 threads load and store straight across
    if ($mode eq 'linear')
    {
        return q|
            // ldx2   = ldx * 2;
            // tid128 = tid & 127;
            // track0 = blk*128 + tid128;
            --:-:-:-:1      IADD ldx2, ldx, ldx;
            --:-:-:-:1      LOP.AND tid128, tid, 0x7f;
            --:-:-:-:1      ISCADD  track0, blk, tid128, 0x7;

            // Setup 8 independent track vars so we don't need to synchronize between texture loads
            --:-:-:-:1      IADD track1, track0, ldx;
            --:-:-:-:1      IADD track2, track0, ldx2;
            --:-:-:-:1      IADD track3, track1, ldx2;
            --:-:-:-:1      IADD track4, track0, ldx4;
            --:-:-:-:1      IADD track5, track1, ldx4;
            --:-:-:-:1      IADD track6, track2, ldx4;
            --:-:-:-:1      IADD track7, track3, ldx4;

            // writeS = tid128 * 4
            --:-:-:-:1      SHL  writeS, tid128, 0x2;
        |;
    }
    # Block Mode: 4 groups of 32 threads stacked on top of each other
    else
    {
        return q|
            // track0 = blk*128 + tid32 + (ldx * tid4)
            --:-:-:-:1      ISCADD  track0, blk, tid32, 0x7;
            --:-:-:-:1      XMAD.LO track0, ldx, tid4,  track0, xmad0; // XMAD.LO is a macro that is expanded out into the 3 XMADs

            // Setup 8 independent track vars so we don't need to synchronize between texture loads
            --:-:-:-:1      IADD track1, track0, 1x<32>;
            --:-:-:-:1      IADD track2, track0, 1x<64>;
            --:-:-:-:1      IADD track3, track0, 1x<96>;
            --:-:-:-:1      IADD track4, track0, ldx4;
            --:-:-:-:1      IADD track5, track1, ldx4;
            --:-:-:-:1      IADD track6, track2, ldx4;
            --:-:-:-:1      IADD track7, track3, ldx4;

            // writeS = (tid32 + tid4*128) * 4
            --:-:-:-:1      ISCADD writeS, tid4,   tid32, 0x7;
            --:-:-:-:1      SHL    writeS, writeS, 0x2;
        |;
    }
</CODE>

// writeS += 4096 if tid >= 128
--:-:-:-:1  @P0 IADD   writeS, writeS, 4x<1024>;

// int end = track0 + (k-8)*ldx;
--:-:-:-:1      MOV k, c[0x0][0x14c];
--:-:-:-:1      IADD k, k, -0x8;
--:-:-:-:1      XMAD.LO end, k, ldx, track0, xmad1;

// readAs and readBs are carefully constructed to avoid any bank conflicts while loading from shared
// readAs = (((tid >> 1) & 7) | ((tid >> 7) << 4)) << 4;
--:-:-:-:1      BFE.U32 val0,   tid,    0x301;
--:-:-:-:1      SHR.U32 readAs, tid,    0x7;
--:-:-:-:1      SHL     readAs, readAs, 0x4;
--:-:-:-:1      LOP.OR  readAs, readAs, val0;
--:-:-:-:1      SHL     readAs, readAs, 0x4;

// readBs  = ((tid & 1) | ((tid >> 3) & 2) | (tid4 << 3)) << 4 + 4096;
--:-:-:-:1      LOP.AND  val1,   tid,  0x1;
--:-:-:-:1      SHR.U32  val2,   tid,  0x3;
--:-:-:-:1      LOP.AND  val2,   val2, 0x2;
--:-:-:-:1      SHL      readBs, tid4, 0x3;
--:-:-:-:1      LOP3.LUT readBs, readBs, val1, val2, 0xfe; // readBs = readBs | val1 | val2
--:-:-:-:1      ISCADD   readBs, readBs, 4x<1024>, 0x4;

// Preload the first 8 lines from texture memory
// Break this up into two barriers so we can load 4 at a time (works faster in main loop so do here as well).
// Keep these instructions in this order (but allow others to interleave).
// Normally the scheduler tries to preserve source order by default, but in this case
// the IADDs to the track variables in linear mode can make a later instruction ready before a preceeding one.
<ORDERED>
--:-:-:-:1      TLD.B.LZ.T loadX0, track0, tex, 0x0, 1D, 0x1;
--:-:-:-:1      TLD.B.LZ.T loadX1, track1, tex, 0x0, 1D, 0x1;
--:-:-:-:1      TLD.B.LZ.T loadX2, track2, tex, 0x0, 1D, 0x1;
--:-:1:-:1      TLD.B.LZ.P loadX3, track3, tex, 0x0, 1D, 0x1; // Set Dep 1
--:-:-:-:1      TLD.B.LZ.T loadX4, track4, tex, 0x0, 1D, 0x1;
--:-:-:-:1      TLD.B.LZ.T loadX5, track5, tex, 0x0, 1D, 0x1;
--:-:-:-:1      TLD.B.LZ.T loadX6, track6, tex, 0x0, 1D, 0x1;
--:-:2:-:1      TLD.B.LZ.P loadX7, track7, tex, 0x0, 1D, 0x1; // Set Dep 2
</ORDERED>

</SCHEDULE_BLOCK>

// These instuctions need to occur after the textures load so put them in a new block
// that starts with a dependency barrier wait.
<SCHEDULE_BLOCK>

<CODE>
    our $mode;

    if ($mode eq 'linear')
    {
        return q|
            01:-:-:-:1      STS [writeS + 4x<0*128>], loadX0; // Wait Dep 1
            --:-:-:-:1      STS [writeS + 4x<1*128>], loadX1;
            --:-:-:-:1      STS [writeS + 4x<2*128>], loadX2;
            --:-:-:-:1      STS [writeS + 4x<3*128>], loadX3;
            02:-:-:-:1      STS [writeS + 4x<4*128>], loadX4; // Wait Dep 2
            --:-:-:-:1      STS [writeS + 4x<5*128>], loadX5;
            --:-:-:-:1      STS [writeS + 4x<6*128>], loadX6;
            --:-:-:-:1      STS [writeS + 4x<7*128>], loadX7;
        |;
    }
    else
    {
        return q|
            01:-:-:-:1      STS [writeS + 4x<000 + 00>], loadX0; // Wait Dep 1
            --:-:-:-:1      STS [writeS + 4x<000 + 32>], loadX1;
            --:-:-:-:1      STS [writeS + 4x<000 + 64>], loadX2;
            --:-:-:-:1      STS [writeS + 4x<000 + 96>], loadX3;
            02:-:-:-:1      STS [writeS + 4x<512 + 00>], loadX4; // Wait Dep 2
            --:-:-:-:1      STS [writeS + 4x<512 + 32>], loadX5;
            --:-:-:-:1      STS [writeS + 4x<512 + 64>], loadX6;
            --:-:-:-:1      STS [writeS + 4x<512 + 96>], loadX7;
        |;
    }
</CODE>

// Increment tracks after the loads are complete to avoid needing write-after-read dependencies
--:-:-:-:1      IADD track0, track0, ldx8;
--:-:-:-:1      IADD track1, track1, ldx8;
--:-:-:-:1      IADD track2, track2, ldx8;
--:-:-:-:1      IADD track3, track3, ldx8;
--:-:-:-:1      IADD track4, track4, ldx8;
--:-:-:-:1      IADD track5, track5, ldx8;
--:-:-:-:1      IADD track6, track6, ldx8;
--:-:-:-:1      IADD track7, track7, ldx8;

// Wait for all threads to finish loading shared
--:-:-:-:5      BAR.SYNC 0x0;

</SCHEDULE_BLOCK>

// Preload the fist lines of A and B from shared
// Initialize C registeres to zero
// Populate the ffma index to C register name mapping
<CODE>

    # We eliminated bank conflicts with our C registers and the blocking registers,
    # but there are still 16 bank conflicts between the blocking registers themselves.
    # By ordering the FFMA's in a specific pattern we can completely hide those conflicts
    # behind register reuse.  This pattern also maximizes that reuse and minimizes the bandwidth
    # out of the register bank, thereby reducing power consumption and allowing the chip to
    # stay at a higher sustained clock speed.
    our @cOrder = qw(
        x02y00 x00y00 x00y01 x02y01 x01y00 x03y00 x01y01 x03y01
        x32y00 x34y00 x32y01 x34y01 x33y00 x35y00 x33y01 x35y01
        x33y02 x35y02 x33y03 x35y03 x32y02 x34y02 x32y03 x34y03
        x01y02 x03y02 x01y03 x03y03 x00y02 x02y02 x00y03 x02y03
        x00y16 x02y16 x00y17 x02y17 x01y16 x03y16 x01y17 x03y17
        x32y16 x34y16 x32y17 x34y17 x33y16 x35y16 x33y17 x35y17
        x33y18 x35y18 x33y19 x35y19 x32y18 x34y18 x32y19 x34y19
        x01y18 x03y18 x01y19 x03y19 x00y18 x02y18 x00y19 x02y19
    );

    my %insert =
    (
        0  => "--:-:-:-:1      LDS.U.128 j0Ax00, [readAs + 4x<0*128 + 00>];\n",
        2  => "--:-:-:-:1      LDS.U.128 j0By00, [readBs + 4x<0*128 + 00>];\n",
        4  => "--:-:-:-:1      LDS.U.128 j0Ax32, [readAs + 4x<0*128 + 32>];\n",
        6  => "--:-:1:-:1      LDS.U.128 j0By16, [readBs + 4x<0*128 + 16>]; // Set Dep 1\n",
    );

    my $out;
    foreach my $c (0 .. 63)
    {
        # Interleave the load instructions with the zeroing instructions
        my ($ins, $stall) = exists $insert{$c} ? ($insert{$c}, 0) : ('', 1);

        $out .= "--:-:-:-:$stall      MOV c$cOrder[$c], RZ;\n$ins";
    }
    return $out;

</CODE>

// Next store to shared goes to high area.
// Having 2 share buffers allows us to eliminate a bar.sync in the main loop
--:-:-:-:1      LOP.XOR writeS, writeS, 4x<2048>;

// The main loop
// While calculating the first line, load in the next line from shared.
// Shared memory stores enough to do this 8 times per loop.
// Also pull in the next block of memory from global and store it to shared.

// Efficiency:
// ffma: 512
// lds:  32 dual issued
// sts:  8  dual issued
// tex:  8  dual issued
// add:  8
// xor:  3
// setp: 1
// bar:  1  dual issued
// bra:  1  dual issued
// Total: 524 (512/524 = 97.7% FFMA)

LOOP:

// Loop end condition
--:-:-:-:1      ISETP.LE.AND P0, PT, track0, end, PT;

<CODE>

    # Shared global var between CODE sections
    our @cOrder;
    our $mode;

    my %insert =
    (
        # Don't start the first TLD before 12 to let ISETP to write P0
        # These global reads and shared writes we put exactly in the middle of the LDS ops
        # This is to not overwhelm the memory units with instructions (and because these were tested faster here).
        j0c29 => "--:-:-:-:1  \@P0 TLD.B.LZ.T loadX0, track0, tex, 0x0, 1D, 0x1;\n",
        j0c31 => "--:-:-:-:1  \@P0 TLD.B.LZ.T loadX1, track1, tex, 0x0, 1D, 0x1;\n",
        j0c33 => "--:-:-:-:1  \@P0 TLD.B.LZ.T loadX2, track2, tex, 0x0, 1D, 0x1;\n",
        j0c35 => "--:-:2:-:1  \@P0 TLD.B.LZ.P loadX3, track3, tex, 0x0, 1D, 0x1; // Set Dep 2\n",

        j1c29 => "--:-:-:-:1  \@P0 TLD.B.LZ.T loadX4, track4, tex, 0x0, 1D, 0x1;\n",
        j1c31 => "--:-:-:-:1  \@P0 TLD.B.LZ.T loadX5, track5, tex, 0x0, 1D, 0x1;\n",
        j1c33 => "--:-:-:-:1  \@P0 TLD.B.LZ.T loadX6, track6, tex, 0x0, 1D, 0x1;\n",
        j1c35 => "--:-:3:-:1  \@P0 TLD.B.LZ.P loadX7, track7, tex, 0x0, 1D, 0x1; // Set Dep 3\n",

        ($mode eq 'linear' ?
            (

                j5c29 => "02:-:-:-:1  \@P0 STS [writeS + 4x<0*128>], loadX0;       // Wait Dep 2\n",
                j5c31 => "--:-:-:-:1  \@P0 STS [writeS + 4x<1*128>], loadX1;\n",
                j5c33 => "--:-:-:-:1  \@P0 STS [writeS + 4x<2*128>], loadX2;\n",
                j5c35 => "--:-:-:-:1  \@P0 STS [writeS + 4x<3*128>], loadX3;\n",

                j6c29 => "04:-:-:-:1  \@P0 STS [writeS + 4x<4*128>], loadX4;       // Wait Dep 3\n",
                j6c31 => "--:-:-:-:1  \@P0 STS [writeS + 4x<5*128>], loadX5;\n",
                j6c33 => "--:-:-:-:1  \@P0 STS [writeS + 4x<6*128>], loadX6;\n",
                j6c35 => "--:-:-:-:1  \@P0 STS [writeS + 4x<7*128>], loadX7;\n",
            ) :
            (
                j5c29 => "02:-:-:-:1  \@P0 STS [writeS + 4x<000 + 00>], loadX0;       // Wait Dep 2\n",
                j5c31 => "--:-:-:-:1  \@P0 STS [writeS + 4x<000 + 32>], loadX1;\n",
                j5c33 => "--:-:-:-:1  \@P0 STS [writeS + 4x<000 + 64>], loadX2;\n",
                j5c35 => "--:-:-:-:1  \@P0 STS [writeS + 4x<000 + 96>], loadX3;\n",

                j6c29 => "04:-:-:-:1  \@P0 STS [writeS + 4x<512 + 00>], loadX4;       // Wait Dep 3\n",
                j6c31 => "--:-:-:-:1  \@P0 STS [writeS + 4x<512 + 32>], loadX5;\n",
                j6c33 => "--:-:-:-:1  \@P0 STS [writeS + 4x<512 + 64>], loadX6;\n",
                j6c35 => "--:-:-:-:1  \@P0 STS [writeS + 4x<512 + 96>], loadX7;\n",
            )
        ),

        # We need one barrier in the main loop after writing shared memory.
        # Note, BAR.SYNCs do not sync memory read access automatically, you still need to flag the barriers (writes are sync'd).
        # After the BAR, swap our share buffer location.  We don't need an additional barrier because of these swaps.
        # Note, this doubles our shared memory usage but this kernel's occupancy is entirely bound by registers.
        # LOP.XOR readAs needs to be 4 clocks prior to the LDS.U.128 for readAs (but push this as far down as possible)
        j6c62 =>
                "01:-:-:-:5  \@P0 BAR.SYNC 0x0; // Wait Dep 1\n" .
                "--:-:-:-:1  \@P0 LOP.XOR readAs, readAs, 4x<2048>;\n" .
                "--:-:-:-:1  \@P0 LOP.XOR readBs, readBs, 4x<2048>;\n" .
                "--:-:-:-:1  \@P0 LOP.XOR writeS, writeS, 4x<2048>;\n",

        # Note having 8 IADDs slightly hits our FFMA performance (8/520 = 1.5%), but TLD doesn't take an offset.
        # LDG.CI doesn't have this issue, but doesn't give you the nice features of texture loads:
        #   -Boundry Clamping:  simplifies our matrix load logic so we don't need to worry about loading out of bounds
        #   -Normalized Floats: if we don't need full 32 bits of precision we could store our matrices using 16 or 8 bit values
        j7c63 =>
                "--:-:-:-:1  \@P0 IADD track0, track0, ldx8;\n" .
                "--:-:-:-:1  \@P0 IADD track1, track1, ldx8;\n" .
                "--:-:-:-:1  \@P0 IADD track2, track2, ldx8;\n" .
                "--:-:-:-:1  \@P0 IADD track3, track3, ldx8;\n" .
                "--:-:-:-:1  \@P0 IADD track4, track4, ldx8;\n" .
                "--:-:-:-:1  \@P0 IADD track5, track5, ldx8;\n" .
                "--:-:-:-:1  \@P0 IADD track6, track6, ldx8;\n" .
                "--:-:-:-:0  \@P0 IADD track7, track7, ldx8;\n" .
                "--:-:-:Y:5  \@P0 BRA LOOP;\n",
    );

    my $out;
    # We unroll our main loop 8 iterations
    # This gives ample time for our textures to load.
    # We could unroll further but that increases the size of the program and increase instruction fetch latency on the branches.
    # We'd also need more shared memory to buffer the lines and more registers to store texture loads.
    # With metaprogramming you could parameterize all this and autotune this implementation for your matrix sizes.
    foreach my $j (0 .. 7)
    {
        my $odd      = $j & 1;
        my $nOdd     = $odd ? 0 : 1;
        # Our rolling blocking registers stay one load ahead off the FFMA's
        my $rsOffset = ($j + 1) % 8;
        # No need to load on last loop iteration
        my $rsPred   = $j == 7 ? '@P0' : '   ';

        # You can experiment here with different vector load sizes
        my $vec = 128;

        if ($vec == 128)
        {
            # Roll up our LDS ops here to keep them easier to manage and tune
            $insert{"j${j}c0"} = sprintf "--:-:-:-:1  %s LDS.U.128 j%dAx00, [readAs + 4x<%d*128 + 00>];\n", $rsPred, $nOdd, $rsOffset;
            $insert{"j${j}c2"} = sprintf "--:-:-:-:1  %s LDS.U.128 j%dBy00, [readBs + 4x<%d*128 + 00>];\n", $rsPred, $nOdd, $rsOffset;
            $insert{"j${j}c4"} = sprintf "--:-:-:-:1  %s LDS.U.128 j%dAx32, [readAs + 4x<%d*128 + 32>];\n", $rsPred, $nOdd, $rsOffset;
            $insert{"j${j}c6"} = sprintf "--:-:1:-:1  %s LDS.U.128 j%dBy16, [readBs + 4x<%d*128 + 16>]; // Set Dep 1\n", $rsPred, $nOdd, $rsOffset;
        }
        elsif ($vec == 64)
        {
            # LDS.128 runs about 40 Gflops faster than LDS.64 (GM107).  Not a huge difference since our latencies are so well hidden.
            # I think LDS.128 is implemented internally as a pair of LDS.64 ops which could be another reason for the comparable performance.
            # I think the big benefit with 128 is being able to issue all our LDS ops earlier, allowing more FFMA's prior to reading out the results.
            $insert{"j${j}c0"}  = sprintf "--:-:-:-:1  %s LDS.U.64 j%dAx00, [readAs + 4x<%d*128 + 00>];\n", $rsPred, $nOdd, $rsOffset;
            $insert{"j${j}c2"}  = sprintf "--:-:-:-:1  %s LDS.U.64 j%dAx02, [readAs + 4x<%d*128 + 02>];\n", $rsPred, $nOdd, $rsOffset;
            $insert{"j${j}c4"}  = sprintf "--:-:-:-:1  %s LDS.U.64 j%dBy00, [readBs + 4x<%d*128 + 00>];\n", $rsPred, $nOdd, $rsOffset;
            $insert{"j${j}c6"}  = sprintf "--:-:-:-:1  %s LDS.U.64 j%dBy02, [readBs + 4x<%d*128 + 02>];\n", $rsPred, $nOdd, $rsOffset;
            $insert{"j${j}c8"}  = sprintf "--:-:-:-:1  %s LDS.U.64 j%dAx32, [readAs + 4x<%d*128 + 32>];\n", $rsPred, $nOdd, $rsOffset;
            $insert{"j${j}c10"} = sprintf "--:-:-:-:1  %s LDS.U.64 j%dAx34, [readAs + 4x<%d*128 + 34>];\n", $rsPred, $nOdd, $rsOffset;
            $insert{"j${j}c12"} = sprintf "--:-:-:-:1  %s LDS.U.64 j%dBy16, [readBs + 4x<%d*128 + 16>];\n", $rsPred, $nOdd, $rsOffset;
            $insert{"j${j}c14"} = sprintf "--:-:1:-:1  %s LDS.U.64 j%dBy18, [readBs + 4x<%d*128 + 18>]; // Set Dep 1\n", $rsPred, $nOdd, $rsOffset;
        }
        else
        {
            # This one drops performance by about 200 Gflops.  So you want to at least use LDS.64 if you can.
            $insert{"j${j}c0"}  = sprintf "--:-:-:-:1  %s LDS j%dAx00, [readAs + 4x<%d*128 + 00>];\n", $rsPred, $nOdd, $rsOffset;
            $insert{"j${j}c1"}  = sprintf "--:-:-:-:1  %s LDS j%dAx01, [readAs + 4x<%d*128 + 01>];\n", $rsPred, $nOdd, $rsOffset;
            $insert{"j${j}c2"}  = sprintf "--:-:-:-:1  %s LDS j%dAx02, [readAs + 4x<%d*128 + 02>];\n", $rsPred, $nOdd, $rsOffset;
            $insert{"j${j}c3"}  = sprintf "--:-:-:-:1  %s LDS j%dAx03, [readAs + 4x<%d*128 + 03>];\n", $rsPred, $nOdd, $rsOffset;
            $insert{"j${j}c4"}  = sprintf "--:-:-:-:1  %s LDS j%dBy00, [readBs + 4x<%d*128 + 00>];\n", $rsPred, $nOdd, $rsOffset;
            $insert{"j${j}c5"}  = sprintf "--:-:-:-:1  %s LDS j%dBy01, [readBs + 4x<%d*128 + 01>];\n", $rsPred, $nOdd, $rsOffset;
            $insert{"j${j}c6"}  = sprintf "--:-:-:-:1  %s LDS j%dBy02, [readBs + 4x<%d*128 + 02>];\n", $rsPred, $nOdd, $rsOffset;
            $insert{"j${j}c7"}  = sprintf "--:-:-:-:1  %s LDS j%dBy03, [readBs + 4x<%d*128 + 03>];\n", $rsPred, $nOdd, $rsOffset;
            $insert{"j${j}c8"}  = sprintf "--:-:-:-:1  %s LDS j%dAx32, [readAs + 4x<%d*128 + 32>];\n", $rsPred, $nOdd, $rsOffset;
            $insert{"j${j}c9"}  = sprintf "--:-:-:-:1  %s LDS j%dAx33, [readAs + 4x<%d*128 + 33>];\n", $rsPred, $nOdd, $rsOffset;
            $insert{"j${j}c10"} = sprintf "--:-:-:-:1  %s LDS j%dAx34, [readAs + 4x<%d*128 + 34>];\n", $rsPred, $nOdd, $rsOffset;
            $insert{"j${j}c11"} = sprintf "--:-:-:-:1  %s LDS j%dAx35, [readAs + 4x<%d*128 + 35>];\n", $rsPred, $nOdd, $rsOffset;
            $insert{"j${j}c12"} = sprintf "--:-:-:-:1  %s LDS j%dBy16, [readBs + 4x<%d*128 + 16>];\n", $rsPred, $nOdd, $rsOffset;
            $insert{"j${j}c13"} = sprintf "--:-:-:-:1  %s LDS j%dBy17, [readBs + 4x<%d*128 + 17>];\n", $rsPred, $nOdd, $rsOffset;
            $insert{"j${j}c14"} = sprintf "--:-:1:-:1  %s LDS j%dBy18, [readBs + 4x<%d*128 + 18>];\n", $rsPred, $nOdd, $rsOffset;
            $insert{"j${j}c15"} = sprintf "--:-:1:-:1  %s LDS j%dBy19, [readBs + 4x<%d*128 + 19>]; // Set Dep 1\n", $rsPred, $nOdd, $rsOffset;
        }
        foreach my $c (0 .. 63)
        {
            my ($x,$y) = $cOrder[$c] =~ /^(x\d+)(y\d+)/;

            # Grab an instruction for insertion if one exists for this j and c combination
            my $ins    = $insert{"j${j}c$c"} || '';

            # Scatter some yields in there to better balance the workload and reduce sync stalls
            # Don't pair a yeild with the dual issued ffmas as that kills performance for some reason
            my $yield  = $c == 28 ? 'Y' : '-';

            # The first FFMA needs to wait on the prior loop's LDS.U.128 ops to finish (except if the barrier does the wait for us)
            my ($waitDB, $comment) = $c == 0 && $j < 7 ? ('01', ' // Wait Dep 1') : ('--','');

            # Dual issue these ops
            my $stall  = $ins =~ /LDS|TLD|STS|BAR/ ? 0 : 1;

            my $ctrl   = "$waitDB:-:-:$yield:$stall";

            # output our FFMA and also any inserted ops
            $out .= sprintf "%s      FFMA c%s, j%dA%s, j%dB%s, c%s;%s\n%s", $ctrl, $cOrder[$c], $odd, $x, $odd, $y, $cOrder[$c], $comment, $ins;
        }
    }
    return $out;

</CODE>

// Main loop is done, time to write C to global memory.
<SCHEDULE_BLOCK>

--:-:-:-:1      MOV ldc, c[0x0][0x158];
--:-:-:-:1      MOV m,   c[0x0][0x144];
--:-:-:-:1      MOV n,   c[0x0][0x148];

// Remap readAs and readBs onto writeCs so we can shuffle the output for coalesced global writes.
// readAs stays constant, readBs colapses down from stride 4 to 1

// Remove the high bit if present from the last loop's xor
--:-:-:-:1      LOP.AND readAs, readAs, 4x<2047>;

//readBs = ((readBs & 0x7f) >> 2) | ((readBs & 0x180) >> 3)
--:-:-:-:1      LOP.AND val3, readBs, 0x180;
--:-:-:-:1      SHR.U32 val3, val3,   0x3;
--:-:-:-:1      BFE.U32 readBs, readBs, 0x502;
--:-:-:-:1      LOP.OR  readBs, readBs, val3;

//writeCs = readBs * 128 + readAs;
--:-:-:-:1      ISCADD  writeCs, readBs, readAs, 0x7;

// Read out the C values from shared in a simple tid mapped pattern but
// expanded back out where collapsed.
//readCs = ((tid4 << 9) | tid32 | ((tid & 0x80) >> 1)) << 2;
--:-:-:-:1      LOP.AND  cx, tid, 0x80;
--:-:-:-:1      SHR.U32  cx, cx, 0x1;
--:-:-:-:1      LOP.OR   cx, tid32, cx;
--:-:-:-:1      SHL      readCs, tid4, 0x9;
--:-:-:-:1      LOP.OR   readCs, readCs, cx;
--:-:-:-:1      SHL      readCs, readCs, 0x2;

// cx = bx*128 + tid32 | ((tid & 0x80) >> 1);
--:-:-:-:1      ISCADD  cx, bx, cx, 0x7;

// cy = by*128 + tid4 << 5;
--:-:-:-:1      SHL cy00, tid4, 0x5;
--:-:-:-:1      ISCADD cy00, by, cy00, 0x7;

// C += (cy*ldc + cx) * 4;
--:-:-:-:1      XMAD.LO ci, cy00, ldc, cx, xmad2;
--:-:-:-:1      ISCADD Cy00, ci, c[0x0][0x140], 0x2;

// When writing in assembly, being able to 'printf' is sometimes easier than stepping through the debugger.
// Here's how it's done.  Drop something like this in your code (math assumes 256 threads and 1 block).
// Then modify the c code to accept this many params per thread to printf (see assemblySgemm function).
//--:-:-:-:1      ISCADD D, tid, c[0x0][0x15c], 0x2;
//--:-:-:-:1      STG.CS [D + 4x<0 * 256>], readAs;
//--:-:-:-:1      STG.CS [D + 4x<1 * 256>], readBs;
//--:-:-:-:1      STG.CS [D + 4x<2 * 256>], writeCs;
//--:-:-:-:1      STG.CS [D + 4x<3 * 256>], readCs;
//--:-:-:-:1      STG.CS [D + 4x<4 * 256>], cx;
//--:-:-:-:1      STG.CS [D + 4x<5 * 256>], cy00;
//--:-:-:-:1      STG.CS [D + 4x<6 * 256>], ci;
//--:-:-:-:1      STG.CS [D + 4x<7 * 256>], cx35y19;

// Setup our matrix bounds checking vars and preds
--:-:-:-:1      ISETP.LT.AND P5, PT, cx, m, PT;
--:-:-:-:1      IADD cx, cx, 0x20;
--:-:-:-:1      ISETP.LT.AND P6, PT, cx, m, PT;

--:-:-:-:1      IADD cy00, cy00, -0x1;
--:-:-:-:1      IADD cy04, cy00,  0x4;
--:-:-:-:1      IADD cy08, cy00,  0x8;
--:-:-:-:1      IADD cy12, cy00,  0xc;

// Setup our C output addresses and increments.
--:-:-:-:1      SHL  ldc1,  ldc, 0x2;
--:-:-:-:1      SHL  ldc4,  ldc, 0x4;
--:-:-:-:1      SHL  ldc8,  ldc, 0x5;
--:-:-:-:1      IADD ldc12, ldc8, ldc4;

--:-:-:-:1      IADD Cy04, Cy00, ldc4;
--:-:-:-:1      IADD Cy08, Cy00, ldc8;
--:-:-:-:1      IADD Cy12, Cy04, ldc8;

// We pre-increment the output addresses to avoid write-after-read deps
// So start with a -1 instead of 0 value.
--:-:-:-:1      IADD Cy00, Cy00, -ldc1;
--:-:-:-:1      IADD Cy04, Cy04, -ldc1;
--:-:-:-:1      IADD Cy08, Cy08, -ldc1;
--:-:-:-:1      IADD Cy12, Cy12, -ldc1;

</SCHEDULE_BLOCK>

// No need to schedule this section
<CODE>

    my $out;
    foreach my $y (0..3, 16..19)
    {
        my ($wait, $comment) = $y ? ('02',' // Wait Dep 2') : ('--','');
        if ($y == 16)
        {
            $out .= q|
--:-:-:-:1      IADD cy00, cy00, 0xc;
--:-:-:-:1      IADD cy04, cy04, 0xc;
--:-:-:-:1      IADD cy08, cy08, 0xc;
--:-:-:-:1      IADD cy12, cy12, 0xc;

02:-:-:-:1      IADD Cy00, Cy00, ldc12; // Wait Dep 2
--:-:-:-:1      IADD Cy04, Cy04, ldc12;
--:-:-:-:1      IADD Cy08, Cy08, ldc12;
--:-:-:-:1      IADD Cy12, Cy12, ldc12;
|;
            $wait = '--';
            $comment = '';
        }
        # We need to move the C values to the param registers of the STORE_C subroutine.
        # Note that these could be FMUL's instead of MOV's if we wanted to multiply the output by alpha.
        $out .= sprintf q|
%s:-:-:-:1      MOV cs0, cx00y%02d;%s
--:-:-:-:1      MOV cs1, cx01y%02d;
--:-:-:-:1      MOV cs2, cx02y%02d;
--:-:-:-:1      MOV cs3, cx03y%02d;
--:-:-:-:1      MOV cs4, cx32y%02d;
--:-:-:-:1      MOV cs5, cx33y%02d;
--:-:-:-:1      MOV cs6, cx34y%02d;
--:-:-:-:0      MOV cs7, cx35y%02d; // Dual Issue
--:-:-:-:5      CAL STORE_C;
|, $wait, $y, $comment, ($y) x 7;

    }
    return $out;

</CODE>

// And we'd done.  The remainder is the STORE_C method that's defined at the end of the kernel.
--:-:-:-:5      EXIT;

// This routine does warp synchronous shuffling of our output data so as to be able
// to have coalesced writes to global memory.  This is actually faster because a
// round trip to shared takes much less time than an extra store to global.
// The SHFL instruction doesn't help us here because we're swaping different registers
// from different threads.
STORE_C:

<SCHEDULE_BLOCK>

// Each warp writes to its own region of memory so we don't need to bar.sync the access.
// There are some bank conflicts here but no way to avoid them, and the hit just means a few extra clocks.
// Note here that the scheduler is able to handle the dependencies between vector and non-vector instructions.
// It knows from the instruction type and the register map that cs0 here includes cs1, cs2 and cs3 as well.
--:-:-:-:1      STS.128 [writeCs+4x<00>], cs0;
--:-:-:-:1      STS.128 [writeCs+4x<32>], cs4;

// Loads naturally occur after the store to shared completes, no sync required.
--:-:-:-:1      LDS cs0, [readCs + 4x<0*128 + 00>];
--:-:-:-:1      LDS cs1, [readCs + 4x<0*128 + 32>];
--:-:-:-:1      LDS cs2, [readCs + 4x<1*128 + 00>];
--:-:-:-:1      LDS cs3, [readCs + 4x<1*128 + 32>];
--:-:-:-:1      LDS cs4, [readCs + 4x<2*128 + 00>];
--:-:-:-:1      LDS cs5, [readCs + 4x<2*128 + 32>];
--:-:-:-:1      LDS cs6, [readCs + 4x<3*128 + 00>];
--:-:1:-:1      LDS cs7, [readCs + 4x<3*128 + 32>]; // Set Dep 1

--:-:-:-:1      IADD cy00, cy00, 0x1;
--:-:-:-:1      IADD cy04, cy04, 0x1;
--:-:-:-:1      IADD cy08, cy08, 0x1;
--:-:-:-:1      IADD cy12, cy12, 0x1;

--:-:-:-:1      IADD Cy00, Cy00, ldc1;
--:-:-:-:1      IADD Cy04, Cy04, ldc1;
--:-:-:-:1      IADD Cy08, Cy08, ldc1;
--:-:-:-:1      IADD Cy12, Cy12, ldc1;

--:-:-:-:1      ISETP.LT.AND P0, PT, cy00, n, P5;
--:-:-:-:1      ISETP.LT.AND P1, PT, cy00, n, P6;
--:-:-:-:1      ISETP.LT.AND P2, PT, cy04, n, P5;
--:-:-:-:1      ISETP.LT.AND P3, PT, cy04, n, P6;

01:-:-:-:1  @P0 STG.CG [Cy00 + 4x<00>], cs0; // Wait Dep 1
--:-:-:-:1  @P1 STG.CG [Cy00 + 4x<32>], cs1;
--:-:-:-:1  @P2 STG.CG [Cy04 + 4x<00>], cs2;
--:-:-:-:1  @P3 STG.CG [Cy04 + 4x<32>], cs3;

--:-:-:-:1      ISETP.LT.AND P0, PT, cy08, n, P5;
--:-:-:-:1      ISETP.LT.AND P1, PT, cy08, n, P6;
--:-:-:-:1      ISETP.LT.AND P2, PT, cy12, n, P5;
--:-:-:-:1      ISETP.LT.AND P3, PT, cy12, n, P6;

--:-:-:-:1  @P0 STG.CG [Cy08 + 4x<00>], cs4;
--:-:-:-:1  @P1 STG.CG [Cy08 + 4x<32>], cs5;
--:-:-:-:1  @P2 STG.CG [Cy12 + 4x<00>], cs6;
--:2:-:-:1  @P3 STG.CG [Cy12 + 4x<32>], cs7; // Set Dep 2

</SCHEDULE_BLOCK>

--:-:-:-:5      RET;

